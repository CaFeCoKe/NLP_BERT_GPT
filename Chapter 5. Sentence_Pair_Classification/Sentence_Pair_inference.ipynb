{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentence_Pair_inference.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"16E1xltN1lbjIOhmbg6XQRthmdixOlBc3","authorship_tag":"ABX9TyO3nM+ZNDdWG+u1qfVAgZTO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 패키지 설치하기"],"metadata":{"id":"NA5vYU_MaozX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1WYCRe4EgfE"},"outputs":[],"source":["!pip install ratsnlp"]},{"cell_type":"markdown","source":["# 환경 설정\n","\n","모델 hyperparameter와 저장 위치 등 설정 정보를 선언"],"metadata":{"id":"GJqdqATZas3h"}},{"cell_type":"code","source":["from ratsnlp.nlpbook.classification import ClassificationDeployArguments"],"metadata":{"id":"HNjwTZsoauLK","executionInfo":{"status":"ok","timestamp":1649493428592,"user_tz":-540,"elapsed":17,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["args = ClassificationDeployArguments(\n","    pretrained_model_name=\"beomi/kcbert-base\",\n","    downstream_model_dir=\"/content/drive/Othercomputers/내 컴퓨터/Chapter 5. Sentence_Pair_Classification/checkpoint-paircls\",\n","    max_seq_length=64,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ntDqfAiBaxn9","executionInfo":{"status":"ok","timestamp":1649493428593,"user_tz":-540,"elapsed":17,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"82b5dd3c-3729-4c6a-eaf0-93dd1ef6c469"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["downstream_model_checkpoint_fpath: /content/drive/Othercomputers/내 컴퓨터/Chapter 5. Sentence_Pair_Classification/checkpoint-paircls/epoch=1-val_loss=0.82.ckpt\n"]}]},{"cell_type":"markdown","source":["# 모델 불러오기\n","\n","파인튜닝을 마친 모델 불러오기"],"metadata":{"id":"whN9inBva6Ph"}},{"cell_type":"code","source":["import torch\n","from transformers import BertConfig, BertForSequenceClassification"],"metadata":{"id":"sH62BmI6a7Yl","executionInfo":{"status":"ok","timestamp":1649493428593,"user_tz":-540,"elapsed":15,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# 체크포인트 로드\n","fine_tuned_model_ckpt = torch.load(\n","    args.downstream_model_checkpoint_fpath,\n","    map_location=torch.device(\"cpu\")\n",")\n","\n","# BERT 설정 로드\n","pretrained_model_config = BertConfig.from_pretrained(\n","    args.pretrained_model_name,\n","    num_labels=fine_tuned_model_ckpt['state_dict']['model.classifier.bias'].shape.numel(),\n",")\n","\n","model = BertForSequenceClassification(pretrained_model_config)      # 모델 초기화\n","model.load_state_dict({k.replace(\"model.\", \"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})     # 체크포인트 주입\n","model.eval()    # 평가모드"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQq-fclna-5i","executionInfo":{"status":"ok","timestamp":1649493434270,"user_tz":-540,"elapsed":5692,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"f73b2d7b-8499-40e2-d21a-78aafb150e61"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(300, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["토크나이저 준비"],"metadata":{"id":"Maq8ib_7bTFY"}},{"cell_type":"code","source":["from transformers import BertTokenizer"],"metadata":{"id":"G_mTjS2QbO7B","executionInfo":{"status":"ok","timestamp":1649493434271,"user_tz":-540,"elapsed":11,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(\n","    args.pretrained_model_name,\n","    do_lower_case=False,\n",")"],"metadata":{"id":"cnbvQpJBbQCg","executionInfo":{"status":"ok","timestamp":1649493435419,"user_tz":-540,"elapsed":1158,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# 인퍼런스 함수"],"metadata":{"id":"wRqWheQjb35f"}},{"cell_type":"code","source":["def inference_fn(premise, hypothesis):\n","\n","    # 입력 문장을 토큰화\n","    inputs = tokenizer(\n","        [(premise, hypothesis)],\n","        max_length=args.max_seq_length,\n","        padding=\"max_length\",\n","        truncation=True,\n","    )\n","\n","    # 평가 모드로 Gradient 업데이트 안함\n","    with torch.no_grad():\n","        outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})  # 토큰화 된 입력 문장을 텐서로 변환 후 모델에 입력\n","        prob = outputs.logits.softmax(dim=1)\n","\n","        # 참, 거짓, 중립 확률을 소수점 두자리에서 반올림\n","        entailment_prob = round(prob[0][0].item(), 2)\n","        contradiction_prob = round(prob[0][1].item(), 2)\n","        neutral_prob = round(prob[0][2].item(), 2)\n","\n","        # 예측 확률의 최대값 위치에 따른 판단 (0:참, 1:거짓, 2:중립)\n","        if torch.argmax(prob) == 0:\n","            pred = \"참 (entailment)\"\n","        elif torch.argmax(prob) == 1:\n","            pred = \"거짓 (contradiction)\"\n","        else:\n","            pred = \"중립 (neutral)\"\n","\n","    return {\n","        'premise': premise,\n","        'hypothesis': hypothesis,\n","        'prediction': pred,\n","        'entailment_data': f\"참 {entailment_prob}\",\n","        'contradiction_data': f\"거짓 {contradiction_prob}\",\n","        'neutral_data': f\"중립 {neutral_prob}\",\n","        'entailment_width': f\"{entailment_prob * 100}%\",\n","        'contradiction_width': f\"{contradiction_prob * 100}%\",\n","        'neutral_width': f\"{neutral_prob * 100}%\",\n","    }"],"metadata":{"id":"S6_B2XGtb6Uf","executionInfo":{"status":"ok","timestamp":1649493435420,"user_tz":-540,"elapsed":10,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# 웹서비스 개시\n","\n","`ngrok` 은 코랩 로컬에서 실행 중인 웹서비스를 안전하게 외부에서 접근 가능하도록 해주는 도구이다. 실행하려면 [회원가입](https://dashboard.ngrok.com/signup) 후 [로그인](https://dashboard.ngrok.com/login)을 한 뒤 [이곳](https://dashboard.ngrok.com/get-started/your-authtoken)에 접속해 인증 토큰(authtoken)을 입력해야 한다."],"metadata":{"id":"RdAlg3Bkb_gN"}},{"cell_type":"code","source":["!mkdir /root/.ngrok2 && echo \"authtoken: {이곳에 확인된 인증 토큰을 입력하세요}\" > /root/.ngrok2/ngrok.yml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olyk6vuGcCGk","executionInfo":{"status":"ok","timestamp":1649493435421,"user_tz":-540,"elapsed":10,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"1af65189-7fa9-4804-f13a-0e8e2624b587"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/root/.ngrok2’: File exists\n"]}]},{"cell_type":"markdown","source":["인퍼런스 함수를 Flask를 통해 웹서비스로 만든다."],"metadata":{"id":"JoglxQNycNGX"}},{"cell_type":"code","source":["from ratsnlp.nlpbook.paircls import get_web_service_app"],"metadata":{"id":"RzZ7lS-WcNlP","executionInfo":{"status":"ok","timestamp":1649493435421,"user_tz":-540,"elapsed":7,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["app = get_web_service_app(inference_fn)\n","app.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdUbFud2cPNg","executionInfo":{"status":"ok","timestamp":1649493839965,"user_tz":-540,"elapsed":404551,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"4e8c2a7c-8d9e-4f70-f537-6542dc80c057"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app \"ratsnlp.nlpbook.paircls.deploy\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":[" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":[" * Running on http://3b7b-35-194-33-249.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"]},{"output_type":"stream","name":"stderr","text":["127.0.0.1 - - [09/Apr/2022 08:37:35] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [09/Apr/2022 08:37:36] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","127.0.0.1 - - [09/Apr/2022 08:37:37] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [09/Apr/2022 08:38:49] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [09/Apr/2022 08:39:24] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [09/Apr/2022 08:40:04] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [09/Apr/2022 08:40:45] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [09/Apr/2022 08:43:00] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [09/Apr/2022 08:43:38] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n"]}]}]}